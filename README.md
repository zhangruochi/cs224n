# [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)


## Introduction and Word Vectors 
- [x] video 
- [x] slide
- [x] notes
- [x] Gensim word vectors example
- [x] Assignment 1
- Suggested Readings
    - [x] Word2Vec Tutorial - The Skip-Gram Model
    - [ ] Efficient Estimation of Word Representations in Vector Space
    - [ ] Distributed Representations of Words and Phrases and their Compositionality 
- [x] Summary


## Word Vectors 2 and Word Senses
- [x] video 
- [x] slide
- [x] notes
- Suggested Readings
    - [ ] GloVe: Global Vectors for Word Representation
    - [ ] Improving Distributional Similarity with Lessons Learned from Word Embeddings
    - [ ] Evaluation methods for unsupervised word embeddings
    - [ ] A Latent Variable Model Approach to PMI-based Word Embeddings
    - [ ] Linear Algebraic Structure of Word Senses, with Applications to Polysemy
    - [ ] On the Dimensionality of Word Embedding.
- [x] Summary

## Python review session 
- [x] slide

## Word Window Classification, Neural Networks, and Matrix Calculus 
- [x] video 
- [ ] slide
- [ ] notes
- [ ] Assignment 2
- Suggested Readings
    - [ ] CS231n notes on backprop
    - [ ] Efficient Estimation of Word Representations in Vector Space
    - [ ] Distributed Representations of Words and Phrases and their Compositionality 
- [] Summary
